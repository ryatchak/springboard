{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import numpy as np\n",
    "import capstone2_utilities as c2 \n",
    "\n",
    "cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_originals = pd.read_csv('tweets_with_originals.csv', parse_dates = ['tweet_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_originals['text_clean'] = tweets_with_originals.text_clean.str.replace(r'@(\\w+)([\\s.,:;!])?', r'\\1 ') # remove @s in @mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "import string\n",
    "#stopwords = stopwords.union(set([i for i in string.punctuation])) # remove punctuation\n",
    "#stopwords = stopwords.union(set(['AmericanAir', 'United', 'USAirways', 'JetBlue', 'SouthwestAir', 'Delta', 'VirginAmerica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"VirginAmerica hi! i'm so excited about your $99 LGA->DAL deal- but i've been trying 2 book since last week & the page never loads. thx!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[55].text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF to identify additional stopwords \n",
    "\n",
    "Using TF-IDF, we'll look for additional stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10)\n",
    "tweet_input = tweets_with_originals.text_clean\n",
    "# maybe try to take out numbers, prices \n",
    "tweet_input=tweet_input.str.replace(r\" (\\d|\\W)+\",\"\") # remove digits, nonword things\n",
    "T = tfidf_vectorizer.fit_transform(tweet_input) # these are our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.120723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.958025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.421465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.609403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.360819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.871644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.181799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_vals\n",
       "count  1628.000000\n",
       "mean      7.120723\n",
       "std       0.958025\n",
       "min       2.421465\n",
       "25%       6.609403\n",
       "50%       7.360819\n",
       "75%       7.871644\n",
       "max       8.181799"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_df = pd.DataFrame(index = tfidf_vectorizer.get_feature_names())\n",
    "idf_df['idf_vals']= tfidf_vectorizer.idf_\n",
    "idf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum inverse document frequency is not so low. For our first pass I won't add any stopwords based on IDF values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this array of tfidf vectors as input features... for testing purposes we'll also allow 2-grams and 3-grams to see if this improves the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10, ngram_range = (1,2))\n",
    "tf3_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10, ngram_range = (1,3))\n",
    "T_2 = tf2_vectorizer.fit_transform(tweet_input) \n",
    "T_3 = tf3_vectorizer.fit_transform(tweet_input)\n",
    "\n",
    "tfidf_input_mats = [T, T_2, T_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll train a word2vec model on our tweets and see what sorts of words are grouped together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "cores = 4 # depends on how many cores you have...\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "tokenized_input = [tokenizer.tokenize(tweet) for tweet in tweet_input.values]\n",
    "tokenized_input = [[word for word in tweet if word not in string.punctuation] for tweet in tokenized_input]\n",
    "model_word2vec = Word2Vec(tokenized_input, window=5, min_count=10, workers=cores) # build vocabulary\n",
    "\n",
    "model_word2vec.train(tokenized_input, total_examples=len(tokenized_input), epochs=10)\n",
    "model_word2vec.save('airlinetweet_word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look ok, airlines are associated with other airlines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/nlp/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('jetblue', 0.8768449425697327),\n",
       " ('americanair', 0.8266503810882568),\n",
       " ('southwestair', 0.8174761533737183),\n",
       " ('usairways', 0.780196487903595),\n",
       " ('virginamerica', 0.6700769662857056),\n",
       " ('mind', 0.4904249310493469),\n",
       " ('guess', 0.4821639657020569),\n",
       " ('god', 0.48063167929649353),\n",
       " ('that', 0.4727621376514435),\n",
       " ('report', 0.46082931756973267)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('united')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('americanair', 0.8229646682739258),\n",
       " ('united', 0.7801964282989502),\n",
       " ('jetblue', 0.7441019415855408),\n",
       " ('southwestair', 0.7262108325958252),\n",
       " ('mind', 0.4514126181602478),\n",
       " ('virginamerica', 0.4489743709564209),\n",
       " ('already', 0.42902764678001404),\n",
       " ('guess', 0.41906771063804626),\n",
       " ('god', 0.4001840353012085),\n",
       " ('worries', 0.39466479420661926)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('usairways')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And TSA with security check type things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pre', 0.8713743090629578),\n",
       " ('name', 0.7713217735290527),\n",
       " ('receipt', 0.7228171825408936),\n",
       " ('stuff', 0.718065619468689),\n",
       " ('fare', 0.7146759033203125),\n",
       " ('passenger', 0.707695484161377),\n",
       " ('file', 0.7035782337188721),\n",
       " ('request', 0.6978631019592285),\n",
       " ('reservation', 0.697336733341217),\n",
       " ('res', 0.6936311721801758)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('tsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec Model\n",
    "\n",
    "Doc2Vec learns \"document\" vectors instead of word vectors. We view each tweet as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "sentiment_tweets_docs = [TaggedDocument(tokenized_input[i], [str(tweets_with_originals.tweet_id.iloc[i])]) for i in range(tweet_input.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec = Doc2Vec(dm=1, vector_size=300, hs=1, window=5,\n",
    "                        min_count=10, sample=0, epochs=20, alpha = .4, \n",
    "                        workers=cores, dbow_words = 1)\n",
    "model_doc2vec.build_vocab(sentiment_tweets_docs)\n",
    "model_doc2vec.train(sentiment_tweets_docs, total_examples = len(sentiment_tweets_docs), epochs = 20)\n",
    "model_doc2vec.save('airlinetweet_doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('its', 0.8927080631256104),\n",
       " ('refuse', 0.8921086192131042),\n",
       " ('supposed', 0.88742595911026),\n",
       " ('nyc', 0.8818486928939819),\n",
       " ('gave', 0.8734860420227051),\n",
       " ('directly', 0.8725155591964722),\n",
       " ('wont', 0.8711974024772644),\n",
       " ('empty', 0.8696985244750977),\n",
       " ('hr', 0.8695963621139526),\n",
       " ('✌', 0.8670365810394287)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc2vec.wv.most_similar('late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sadly', 0.9078196287155151),\n",
       " ('attendant', 0.8967957496643066),\n",
       " (\"aren't\", 0.8942638635635376),\n",
       " ('value', 0.8760038018226624),\n",
       " ('security', 0.8725130558013916),\n",
       " ('tickets', 0.8679995536804199),\n",
       " ('happen', 0.8668830394744873),\n",
       " ('refund', 0.8644219636917114),\n",
       " ('these', 0.8557482957839966),\n",
       " ('the', 0.8526627421379089)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc2vec.wv.most_similar('delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', 0.8749268651008606),\n",
       " ('cost', 0.8416961431503296),\n",
       " ('helped', 0.8233813047409058),\n",
       " ('b4', 0.8098344206809998),\n",
       " ('own', 0.8066888451576233),\n",
       " ('extra', 0.8050414323806763),\n",
       " ('advantage', 0.8027144074440002),\n",
       " ('i', 0.7969229221343994),\n",
       " (\"let's\", 0.7958469390869141),\n",
       " ('got', 0.7866212725639343)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc2vec.wv.most_similar('tsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('570247763704868864', 0.9152392148971558),\n",
       " ('568997044406374400', 0.8972954750061035),\n",
       " ('569918327767879680', 0.8908112645149231),\n",
       " ('568873459901702145', 0.890682578086853),\n",
       " ('568200350697717760', 0.8859471082687378),\n",
       " ('567782645975625729', 0.8823562264442444),\n",
       " ('570177752973885440', 0.8798604011535645),\n",
       " ('570138826032713729', 0.8785470128059387),\n",
       " ('570251909447192577', 0.8723245859146118),\n",
       " ('568086073814827008', 0.8720375299453735)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc2vec.docvecs.most_similar('570085644015419393')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tweets are quite similar according to the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"USAirways  A few years ago I lost over 50,00 miles bc I was physically unable to fly during the period.  I submitted a doctor's note.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[tweets_with_originals.tweet_id == 570085644015419393]['text_clean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SouthwestAir Teyana Taylor Performing #MedusaFridays 2[.] 27 Free Till11   #TheMenOfBusiness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[tweets_with_originals.tweet_id == 570274362936266752]['text_clean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USAirways #usairways lost a passenger today for not upholding their promise of excellent customer service!!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[tweets_with_originals.tweet_id == 569734884396302338]['text_clean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jetblue having trouble signing in to TrueBlue today, despite right credentials. getting \"We are not able to sign you in\" msg.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[tweets_with_originals.tweet_id == 570277054635057153]['text_clean'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are at least all negative sentiment tweets, so hopefully we're heading in the right direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: different models with different hyperparameters, methods (DBOW vs not etc) as a list, test train split on all of these to test model (better accuracy -> better model (ish) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_doc2vec = Doc2Vec(dm=0, vector_size=300, negative=5, window=5,\n",
    "                        min_count=10, sample=1e-5, epochs=20, \n",
    "                        workers=cores, dbow_words = 1)\n",
    "model_2_doc2vec.build_vocab(sentiment_tweets_docs)\n",
    "model_2_doc2vec.train(sentiment_tweets_docs, total_examples = len(sentiment_tweets_docs), epochs = 20)\n",
    "model_2_doc2vec.save('airlinetweet_doc2vec_2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('march', 0.9995496869087219),\n",
       " ('fam', 0.9995301961898804),\n",
       " ('welcome', 0.9995203614234924),\n",
       " ('rewards', 0.9995168447494507),\n",
       " ('✈', 0.999514639377594),\n",
       " ('mine', 0.9995139837265015),\n",
       " ('clothes', 0.9995129704475403),\n",
       " ('social', 0.9995110034942627),\n",
       " ('flightn', 0.9995100498199463),\n",
       " ('enter', 0.9995092749595642)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_doc2vec.wv.most_similar('late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_doc2vec = Doc2Vec(dm=0, vector_size=300, negative=5, window=5,\n",
    "                        min_count=10, sample=1e-5, epochs=20, \n",
    "                        workers=cores, dbow_words = 1)\n",
    "model_3_doc2vec.build_vocab(sentiment_tweets_docs)\n",
    "model_3_doc2vec.train(sentiment_tweets_docs, total_examples = len(sentiment_tweets_docs), epochs = 20)\n",
    "model_3_doc2vec.save('airlinetweet_doc2vec_3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fam', 0.9995274543762207),\n",
       " ('alone', 0.9995249509811401),\n",
       " ('between', 0.9995194673538208),\n",
       " ('flightn', 0.999518632888794),\n",
       " ('city', 0.9995133876800537),\n",
       " ('msg', 0.9995127320289612),\n",
       " ('wont', 0.9995114803314209),\n",
       " ('welcome', 0.9995113611221313),\n",
       " ('social', 0.9995094537734985),\n",
       " ('shitty', 0.9995070695877075)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_doc2vec.wv.most_similar('late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_models = [model_doc2vec, model_2_doc2vec, model_3_doc2vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiments in our dataset are highly imbalanced: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x = 'airline_sentiment', data = tweets_with_originals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of strategies we could try to rebalance the dataset. The easiest would be oversampling the neutral/positive sentiment tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test split with oversampling ... try SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "y = tweets_with_originals.airline_sentiment.map({'negative': 0, 'neutral':1, 'positive':2})\n",
    "\n",
    "# test_train split for TFIDF outputs \n",
    "tfidf_learning_inputs = []\n",
    "for M in tfidf_input_mats:\n",
    "    T_train, T_test, y_train, y_test = train_test_split(T, y, test_size=0.3)\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    T_train_sm, y_train_sm = sm.fit_sample(T_train, y_train.ravel())\n",
    "    tfidf_learning_inputs.append([T_train_sm, T_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train_split for Doc2Vec outputs\n",
    "#train\n",
    "tweet_ids = tweets_with_originals.tweet_id.astype(str).values\n",
    "doc2vec_learning_inputs = []\n",
    "for model in doc2vec_models: \n",
    "    X_train, X_test, y_train, y_test = c2.doc2vec_train_test_split(model, tweet_ids, y)\n",
    "    sm = SMOTE()\n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    doc2vec_learning_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that SMOTE balances the number of training samples in each class... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x = tfidf_learning_inputs[0][2])\n",
    "_ = plt.title('Classes in training set after SMOTE')\n",
    "locs, labels = plt.xticks()\n",
    "_ = plt.xticks(locs, ['negative', 'neutral', 'positive'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF input sentiment analysis\n",
    "Basic logistic regression with one-versus-rest (OVR) multiclass scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram TF-IDF:\t Accuracy 0.7502879520847731\n",
      "2-gram TF-IDF:\t Accuracy 0.7403824003685787\n",
      "3-gram TF-IDF:\t Accuracy 0.75074867542041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf_log_models = []\n",
    "for i, ngram_model in enumerate(tfidf_learning_inputs): \n",
    "    lr = LogisticRegression(solver = 'lbfgs', multi_class='auto', max_iter = 200)\n",
    "    lr.fit(ngram_model[0], ngram_model[2])\n",
    "    print('{}-gram TF-IDF:\\t Accuracy {}'.format(i+1,lr.score(ngram_model[1], ngram_model[3])))\n",
    "    tfidf_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec input sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the sum of words embedding which is described [here](https://white.ucc.asn.au/publications/White2015SentVecMeaning.pdf). We just take the sum of the word vectors contained in a tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vec = tweets_with_originals.set_index('tweet_id').airline_sentiment.map({'negative': 0, 'neutral':1, 'positive':2})\n",
    "tokenized_input_ser = pd.Series(tokenized_input, index=tweets_with_originals.tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sow_inputs = []\n",
    "for model in doc2vec_models:\n",
    "    X_train, X_test, y_train, y_test = c2.word2vec_train_test_split(model_word2vec, tokenized_input_ser, target_vec)\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    word2vec_sow_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_avg_inputs = []\n",
    "for model in doc2vec_models:\n",
    "    X_train, X_test, y_train, y_test = c2.word2vec_train_test_split(model_word2vec, tokenized_input_ser, target_vec, embedding = 'avge')\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    word2vec_avg_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Sum of words input sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Sum of words Model 1:\t Accuracy 0.6984565768256162\n",
      "Word2Vec Sum of words Model 2:\t Accuracy 0.6933886201336098\n",
      "Word2Vec Sum of words Model 3:\t Accuracy 0.6922368117945173\n"
     ]
    }
   ],
   "source": [
    "word2vec_sow_log_models = []\n",
    "for i, sow_model in enumerate(word2vec_sow_inputs): \n",
    "    lr = LogisticRegression(solver = 'lbfgs', multi_class='auto', max_iter = 2000)\n",
    "    lr.fit(sow_model[0], sow_model[2])\n",
    "    print('Word2Vec Sum of words Model {}:\\t Accuracy {}'.format(i+1,lr.score(sow_model[1], sow_model[3])))\n",
    "    word2vec_sow_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Avg embedding input sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Mean Embedding Model 1:\t Accuracy 0.6998387468325271\n",
      "Word2Vec Mean Embedding Model 2:\t Accuracy 0.6848652384243262\n",
      "Word2Vec Mean Embedding Model 3:\t Accuracy 0.6975351301543423\n"
     ]
    }
   ],
   "source": [
    "word2vec_avg_log_models = []\n",
    "for i, avg_model in enumerate(word2vec_avg_inputs): \n",
    "    lr = LogisticRegression(solver = 'lbfgs', multi_class='auto', max_iter = 2000)\n",
    "    lr.fit(avg_model[0], avg_model[2])\n",
    "    print('Word2Vec Mean Embedding Model {}:\\t Accuracy {}'.format(i+1,lr.score(avg_model[1], avg_model[3])))\n",
    "    word2vec_avg_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average and sum of word embeddings for tweets seem to perform comparably: this is in line with what we'd expect from the literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec input sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/nlp/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.2976272748214697\n",
      "Model 2: \t Accuracy 0.5215388159410275\n",
      "Model 3: \t Accuracy 0.5088689242110113\n"
     ]
    }
   ],
   "source": [
    "doc2vec_log_models = []\n",
    "for i,model in enumerate(doc2vec_learning_inputs): \n",
    "    lr = LogisticRegression(solver='lbfgs', multi_class = 'auto', max_iter = 500)\n",
    "    lr.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1, lr.score(model[1], model[3])))\n",
    "    doc2vec_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is poor here: instability was observed in results when training the various Doc2Vec models. I think that we need more training data: the number of tweets we have is pretty low for the complexity of the doc2vec NN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram TF-IDF:\t Accuracy 0.6913153651232435\n",
      "2-gram TF-IDF:\t Accuracy 0.7007601935038009\n",
      "3-gram TF-IDF:\t Accuracy 0.7079014052061737\n"
     ]
    }
   ],
   "source": [
    "tfidf_rf_models = []\n",
    "for i, ngram_model in enumerate(tfidf_learning_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 200, criterion = 'gini', max_features = 'sqrt', max_depth = 20)\n",
    "    rf.fit(ngram_model[0], ngram_model[2])\n",
    "    print('{}-gram TF-IDF:\\t Accuracy {}'.format(i+1,rf.score(ngram_model[1], ngram_model[3])))\n",
    "    tfidf_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.7115871918912693\n",
      "Model 2: \t Accuracy 0.7159640635798203\n",
      "Model 3: \t Accuracy 0.7067495968670813\n"
     ]
    }
   ],
   "source": [
    "word2vec_sow_rf_models = []\n",
    "for i, model in enumerate(word2vec_sow_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    word2vec_sow_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.7113568302234509\n",
      "Model 2: \t Accuracy 0.686708131766874\n",
      "Model 3: \t Accuracy 0.7062888735314443\n"
     ]
    }
   ],
   "source": [
    "word2vec_avg_rf_models = []\n",
    "for i, model in enumerate(word2vec_avg_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    word2vec_avg_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.4621055056438609\n",
      "Model 2: \t Accuracy 0.5844275512554711\n",
      "Model 3: \t Accuracy 0.5883436996083852\n"
     ]
    }
   ],
   "source": [
    "doc2vec_rf_models = []\n",
    "for i, model in enumerate(doc2vec_learning_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    doc2vec_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 67.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 212.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 381.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With thanks to towardsdatascience: \n",
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(word2vec_sow_inputs[0][0], word2vec_sow_inputs[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.7313982953236582\n",
      "Model 2: \t Accuracy 0.7461414420640405\n",
      "Model 3: \t Accuracy 0.7415342087076711\n"
     ]
    }
   ],
   "source": [
    "word2vec_sow_rf_models = []\n",
    "for i, model in enumerate(word2vec_sow_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 1000, criterion = 'gini', max_features = 'sqrt', max_depth = 70, \n",
    "                               min_samples_split=2, min_samples_leaf = 1)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    word2vec_sow_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
