{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import numpy as np\n",
    "import capstone2_utilities as c2 \n",
    "\n",
    "cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_originals = pd.read_csv('tweets_with_originals.csv', parse_dates = ['tweet_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_originals['text_clean'] = tweets_with_originals.text_clean.str.replace(r'@(\\w+)([\\s.,:;!])?', r'\\1 ') # remove @s in @mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "import string\n",
    "#stopwords = stopwords.union(set([i for i in string.punctuation])) # remove punctuation\n",
    "#stopwords = stopwords.union(set(['AmericanAir', 'United', 'USAirways', 'JetBlue', 'SouthwestAir', 'Delta', 'VirginAmerica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"VirginAmerica hi! i'm so excited about your $99 LGA-&gt;DAL deal- but i've been trying 2 book since last week &amp; the page never loads. thx!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_originals.loc[55].text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF to identify additional stopwords \n",
    "\n",
    "Using TF-IDF, we'll look for additional stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10)\n",
    "tweet_input = tweets_with_originals.text_clean\n",
    "# maybe try to take out numbers, prices \n",
    "tweet_input=tweet_input.str.replace(r\" (\\d|\\W)+\",\"\") # remove digits, nonword things\n",
    "T = tfidf_vectorizer.fit_transform(tweet_input) # these are our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1632.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.119166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.957482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.421178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.609403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.360819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.871644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.181799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_vals\n",
       "count  1632.000000\n",
       "mean      7.119166\n",
       "std       0.957482\n",
       "min       2.421178\n",
       "25%       6.609403\n",
       "50%       7.360819\n",
       "75%       7.871644\n",
       "max       8.181799"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_df = pd.DataFrame(index = tfidf_vectorizer.get_feature_names())\n",
    "idf_df['idf_vals']= tfidf_vectorizer.idf_\n",
    "idf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum inverse document frequency is not so low. For our first pass I won't add any stopwords based on IDF values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this array of tfidf vectors as input features... for testing purposes we'll also allow 2-grams and 3-grams to see if this improves the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10, ngram_range = (1,2))\n",
    "tf3_vectorizer = TfidfVectorizer(stop_words = stopwords, strip_accents = 'unicode', min_df = 10, ngram_range = (1,3))\n",
    "T_2 = tf2_vectorizer.fit_transform(tweet_input) \n",
    "T_3 = tf3_vectorizer.fit_transform(tweet_input)\n",
    "\n",
    "tfidf_input_mats = [T, T_2, T_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll train a word2vec model on our tweets and see what sorts of words are grouped together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "cores = 4 # depends on how many cores you have...\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "tokenized_input = [tokenizer.tokenize(tweet) for tweet in tweet_input.values]\n",
    "tokenized_input = [[word for word in tweet if word not in string.punctuation] for tweet in tokenized_input]\n",
    "model_word2vec = Word2Vec(tokenized_input, window=2, min_count=1, workers=cores) # build vocabulary\n",
    "\n",
    "model_word2vec.train(tokenized_input, total_examples=len(tokenized_input), epochs=10)\n",
    "model_word2vec.save('airlinetweet_word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look ok, airlines are associated with other airlines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/nlp/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('jetblue', 0.858433187007904),\n",
       " ('usairways', 0.7918170690536499),\n",
       " ('americanair', 0.786402702331543),\n",
       " ('southwestair', 0.7863386273384094),\n",
       " ('virginamerica', 0.634326696395874),\n",
       " ('guess', 0.5249053239822388),\n",
       " ('certainly', 0.5245820879936218),\n",
       " ('but', 0.5198203325271606),\n",
       " ('haha', 0.46811652183532715),\n",
       " ('fine', 0.467410683631897)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('united')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('americanair', 0.8042764663696289),\n",
       " ('united', 0.7918170690536499),\n",
       " ('southwestair', 0.7464061975479126),\n",
       " ('jetblue', 0.7016778588294983),\n",
       " ('virginamerica', 0.4542508125305176),\n",
       " ('certainly', 0.4246622323989868),\n",
       " ('happened', 0.41901466250419617),\n",
       " ('idea', 0.414933979511261),\n",
       " ('mind', 0.41486549377441406),\n",
       " ('know', 0.41471704840660095)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('usairways')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And TSA with security check type things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pre', 0.8031080961227417),\n",
       " ('file', 0.7105032801628113),\n",
       " ('receipt', 0.7090972661972046),\n",
       " ('number', 0.7015888690948486),\n",
       " ('name', 0.6989423036575317),\n",
       " ('res', 0.6933581829071045),\n",
       " ('reservation', 0.684999406337738),\n",
       " ('itinerary', 0.6801326870918274),\n",
       " ('request', 0.675376832485199),\n",
       " ('husband', 0.6723905801773071)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar('tsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test a few models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [.01, .075, .05, .025]\n",
    "window = [1,2,3]\n",
    "word2vec_models = []\n",
    "for a in alpha:\n",
    "    for ws in window:\n",
    "        model_word2vec = Word2Vec(tokenized_input, window=ws, alpha = a, min_count=1, workers=cores) # build vocabulary\n",
    "        model_word2vec.train(tokenized_input, total_examples=len(tokenized_input), epochs=50)\n",
    "        word2vec_models.append(model_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec Model\n",
    "\n",
    "Doc2Vec learns \"document\" vectors instead of word vectors. We view each tweet as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "sentiment_tweets_docs = [TaggedDocument(tokenized_input[i], [str(tweets_with_originals.tweet_id.iloc[i])]) for i in range(tweet_input.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = [50,100,150]\n",
    "window = [1,2,3]\n",
    "alg_type = [0, 1] # 0 corresponds to PV-DBOW, 1 to PV-DM\n",
    "\n",
    "doc2vec_models = [] \n",
    "for vs in vector_size:\n",
    "    for w in window: \n",
    "        for d in alg_type:\n",
    "            model_doc2vec = Doc2Vec(dm=d, vector_size=vs, hs=1, window=w,\n",
    "                        min_count=1, sample=0, epochs=100, \n",
    "                        workers=cores, dbow_words = 0)\n",
    "            model_doc2vec.build_vocab(sentiment_tweets_docs)\n",
    "            model_doc2vec.train(sentiment_tweets_docs, total_examples = len(sentiment_tweets_docs), epochs=model_doc2vec.epochs)\n",
    "            doc2vec_models.append(model_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(doc2vec_models, open( \"word2vec_sow_inputs.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll evaluate these models when we get to the logistic regression/ random forest part of the sentiment analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiments in our dataset are highly imbalanced: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFRtJREFUeJzt3X+0ZWV93/H3RwYQJPxyRquAGYLTGLRJlFkIkqZGXIhJKlTBjJUwGtYitkTE1qaa1RYqMQurLRqiJkRQMKSIaBQNFSgKq8XyYxDCT5EpIIwQGeWHohEd+faP/Vw5TO/cOc84Z869M+/XWmfdvZ/97H2+555z7ufuffZ5dqoKSZLG9bRpFyBJWlgMDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXRZNu4BJWLx4cS1dunTaZUjSgnL99dd/u6qWbKzfVhkcS5cuZdWqVdMuQ5IWlCTfGKefh6okSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXbbKb45LWhgOOeOQaZew1bvqrVdt9m26xyFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqctEgyPJ25PcmuSWJP89ydOT7JvkmiR3Jvlkkh1a3x3b/Oq2fOnIdt7V2u9I8qpJ1ixJmtvEgiPJXsCJwPKqehGwHbACeC9welUtAx4GjmurHAc8XFXPB05v/Uiyf1vvhcDhwIeTbDepuiVJc5v0oapFwE5JFgE7Aw8ArwAubMvPAY5s00e0edryQ5OktZ9fVY9X1d3AauDACdctSdqAiQVHVX0TeD9wL0NgPApcDzxSVetatzXAXm16L+C+tu661v+Zo+2zrPNTSY5PsirJqrVr127+ByRJAiZ7qGoPhr2FfYHnAs8AXj1L15pZZQPLNtT+1IaqM6tqeVUtX7JkyaYVLUnaqEkeqnolcHdVra2qHwOfAV4G7N4OXQHsDdzfptcA+wC05bsBD422z7KOJGkLm2Rw3AsclGTn9lnFocBtwJeBo1qflcDn2vRFbZ62/EtVVa19RTvral9gGXDtBOuWJM1h0ca7bJqquibJhcBXgXXADcCZwN8C5yf549Z2VlvlLOATSVYz7GmsaNu5NckFDKGzDjihqn4yqbolSXObWHAAVNXJwMnrNd/FLGdFVdUPgaM3sJ33AO/Z7AVKkrr5zXFJUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldJhocSXZPcmGSryW5PcnBSfZMclmSO9vPPVrfJPnTJKuT3JTkJSPbWdn635lk5SRrliTNbdJ7HB8EvlhVLwB+BbgdeCdweVUtAy5v8wCvBpa12/HARwCS7AmcDLwUOBA4eSZsJElb3sSCI8muwK8DZwFU1Y+q6hHgCOCc1u0c4Mg2fQRwbg2uBnZP8hzgVcBlVfVQVT0MXAYcPqm6JUlzm+Qexy8Aa4GPJbkhyUeTPAN4dlU9ANB+Pqv13wu4b2T9Na1tQ+2SpCmYZHAsAl4CfKSqXgx8nycPS80ms7TVHO1PXTk5PsmqJKvWrl27KfVKksYwyeBYA6ypqmva/IUMQfKtdgiK9vPBkf77jKy/N3D/HO1PUVVnVtXyqlq+ZMmSzfpAJElPmlhwVNXfA/cl+cXWdChwG3ARMHNm1Ergc236IuDYdnbVQcCj7VDWJcBhSfZoH4of1tokSVOwaMLbfytwXpIdgLuANzOE1QVJjgPuBY5ufS8GfhNYDfyg9aWqHkpyKnBd6/fuqnpownVLkjZgosFRVTcCy2dZdOgsfQs4YQPbORs4e/NWJ0naFH5zXJLUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldxgqOJJeP0yZJ2vrNOchhkqcDOwOL25DmMxdV2hV47oRrkyTNQxsbHff3gZMYQuJ6ngyO7wIfmmBdkqR5as7gqKoPAh9M8taqOmML1SRJmsfGuh5HVZ2R5GXA0tF1qurcCdUlSZqnxgqOJJ8A9gNuBH7SmgswOCRpGzPuFQCXA/u3q/RJkrZh436P4xbgH02yEEnSwjDuHsdi4LYk1wKPzzRW1WsmUpUkad4aNzhOmWQRkqSFY9yzqq6cdCGSpIVh3LOqvsdwFhXADsD2wPeratdJFSZJmp/G3eP4udH5JEcCB06kIknSvLZJo+NW1WeBV2zmWiRJC8C4h6peOzL7NIbvdfidDknaBo17VtU/H5leB9wDHLHZq5EkzXvjfsbx5kkXIklaGMa9kNPeSf4myYNJvpXk00n2nnRxkqT5Z9wPxz8GXMRwXY69gM+3NknSNmbc4FhSVR+rqnXt9nFgyQTrkiTNU+MGx7eTHJNku3Y7BvjOJAuTJM1P4wbH7wGvB/4eeAA4CvADc0naBo17Ou6pwMqqehggyZ7A+xkCRZK0DRl3j+OXZ0IDoKoeAl48mZIkSfPZuMHxtCR7zMy0PY5x91YkSVuRcf/4/1fgK0kuZBhq5PXAeyZWlSRp3hprj6OqzgVeB3wLWAu8tqo+Mc667SysG5J8oc3vm+SaJHcm+WSSHVr7jm1+dVu+dGQb72rtdyR5Vd9DlCRtTmOPjltVt1XVn1XVGVV1W8d9vA24fWT+vcDpVbUMeBg4rrUfBzxcVc8HTm/9SLI/sAJ4IXA48OEk23XcvyRpM9qkYdXH1YYl+S3go20+DMOxX9i6nAMc2aaPaPO05Ye2/kcA51fV41V1N7AarwUiSVMz0eAAPgD8IfBEm38m8EhVrWvzaxiGMKH9vA+gLX+09f9p+yzrSJK2sIkFR5LfBh6squtHm2fpWhtZNtc6o/d3fJJVSVatXbu2u15J0ngmucdxCPCaJPcA5zMcovoAsHuSmbO59gbub9NrgH0A2vLdgIdG22dZ56eq6syqWl5Vy5cscRgtSZqUiQVHVb2rqvauqqUMH25/qareCHyZYcgSgJXA59r0RW2etvxLVVWtfUU762pfYBlw7aTqliTNbRpf4vv3wPlJ/hi4ATirtZ8FfCLJaoY9jRUAVXVrkguA2xiuPnhCVf1ky5ctSYItFBxVdQVwRZu+i1nOiqqqHwJHb2D99+AXDiVpXpj0WVWSpK2MwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC7TuALgvHLAvzt32iVsE65/37HTLkHSZuIehySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQu2/yFnLSw3fvufzLtErZ6z/tPN0+7BM0z7nFIkroYHJKkLgaHJKnLxIIjyT5Jvpzk9iS3Jnlba98zyWVJ7mw/92jtSfKnSVYnuSnJS0a2tbL1vzPJyknVLEnauEnucawD/m1V/RJwEHBCkv2BdwKXV9Uy4PI2D/BqYFm7HQ98BIagAU4GXgocCJw8EzaSpC1vYsFRVQ9U1Vfb9PeA24G9gCOAc1q3c4Aj2/QRwLk1uBrYPclzgFcBl1XVQ1X1MHAZcPik6pYkzW2LfMaRZCnwYuAa4NlV9QAM4QI8q3XbC7hvZLU1rW1D7evfx/FJViVZtXbt2s39ECRJzcSDI8kuwKeBk6rqu3N1naWt5mh/akPVmVW1vKqWL1myZNOKlSRt1ESDI8n2DKFxXlV9pjV/qx2Cov18sLWvAfYZWX1v4P452iVJUzDJs6oCnAXcXlX/bWTRRcDMmVErgc+NtB/bzq46CHi0Hcq6BDgsyR7tQ/HDWpskaQomOeTIIcDvAjcnubG1/RFwGnBBkuOAe4Gj27KLgd8EVgM/AN4MUFUPJTkVuK71e3dVPTTBuiVJc5hYcFTV/2b2zycADp2lfwEnbGBbZwNnb77qJEmbym+OS5K6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6rJggiPJ4UnuSLI6yTunXY8kbasWRHAk2Q74EPBqYH/gDUn2n25VkrRtWhDBARwIrK6qu6rqR8D5wBFTrkmStkkLJTj2Au4bmV/T2iRJW9iiaRcwpszSVk/pkBwPHN9mH0tyx8Srmp7FwLenXUSPvH/ltEuYTxbW83fybG+/bdbCeu6AnNj1/P38OJ0WSnCsAfYZmd8buH+0Q1WdCZy5JYualiSrqmr5tOvQpvH5W7h87gYL5VDVdcCyJPsm2QFYAVw05ZokaZu0IPY4qmpdkj8ALgG2A86uqlunXJYkbZMWRHAAVNXFwMXTrmOe2CYOyW3FfP4WLp87IFW18V6SJDUL5TMOSdI8YXAsUEmWJvmXm7juY5u7Hm1ckrckObZNvynJc0eWfdTREBaWJLsn+dcj889NcuE0a9pSPFS1QCV5OfCOqvrtWZYtqqp1c6z7WFXtMsn6NLckVzA8f6umXYs2TZKlwBeq6kVTLmWLc49jC2t7Crcn+csktya5NMlOSfZL8sUk1yf5X0le0Pp/PMlRI+vP7C2cBvzTJDcmeXv7D/ZTST4PXJpklySXJ/lqkpuTOETLz6A9b19Lck6Sm5JcmGTnJIcmuaH9js9OsmPrf1qS21rf97e2U5K8oz2fy4Hz2vO3U5IrkixP8q+S/JeR+31TkjPa9DFJrm3r/EUbw00bsAnvtf2SXJ3kuiTvnnmvzfFeOg3Yrz0f72v3d0tb55okLxyp5YokByR5RnudXNdeNwvzfVlV3rbgDVgKrAN+tc1fABwDXA4sa20vBb7Upj8OHDWy/mPt58sZ/tuZaX8Twxcl92zzi4Bd2/RiYDVP7mE+Nu3fw0K7teetgEPa/NnAf2AYCucft7ZzgZOAPYE7Rn7fu7efpzDsZQBcASwf2f4VDGGyhGFctpn2/wH8GvBLwOeB7Vv7h4Fjp/17mc+3TXivfQF4Q5t+y8h7bdb3Utv+Levd3y1t+u3Af27TzwG+3qb/BDhm5nUBfB14xrR/V7039zim4+6qurFNX8/wgnsZ8KkkNwJ/wfBi63VZVT3UpgP8SZKbgP/JMLbXs3+mqnVfVV3Vpv8KOJThufx6azsH+HXgu8APgY8meS3wg3HvoKrWAnclOSjJM4FfBK5q93UAcF17jRwK/MJmeExbu5732sHAp9r0X49sY1PeSxcAR7fp149s9zDgne2+rwCeDjyv+1FN2YL5HsdW5vGR6Z8wvAgfqapfnaXvOtohxSQBdphju98fmX4jw3+vB1TVj5Pcw/Ai1aYb6wPBGr6weiDDH/cVwB8Ar+i4n08y/LH5GvA3VVXtuT+nqt7VWfO2rue9tiHd76Wq+maS7yT5ZeB3gN9viwK8rqoW9Fh67nHMD98F7k5yNAwBkeRX2rJ7GP7ThGEo+e3b9PeAn5tjm7sBD7YX+m8w5uBlmtPzkhzcpt/A8N/n0iTPb22/C1yZZBdgtxq+tHoSMNsfqbmev88AR7b7+GRruxw4KsmzAJLsmcTntN9c77Wrgde16RUj62zovbSx9+D5wB8yvBZubm2XAG9t/wiQ5MU/6wOaBoNj/ngjcFySvwNu5cnrjfwl8M+SXMtwPHZmr+ImYF2Sv0vy9lm2dx6wPMmqtu2vTbT6bcPtwMp2yGJP4HTgzQyHPW4GngD+nOGPyRdavysZjnev7+PAn898OD66oKoeBm4Dfr6qrm1ttzF8pnJp2+5lbNrhTG34vXYS8G/ae+05wKOtfdb3UlV9B7gqyS1J3jfL/VzIEEAXjLSdyvDP303tg/RTN+sj20I8HVcaQ7bhUy+3FUl2Bv6hHRpcwfBB+cI862nC/IxDkgYHAH/WDiM9AvzelOuZt9zjkCR18TMOSVIXg0OS1MXgkCR1MTgkSV0MDm3VklycZPcNLLsnyeI2/ZUtW9l4kvzRevMTrTPrDRUuzcazqrTNaadbBriLYaDBb0+5pA3KFh4C3++raBzucWirkeSzbajsW5Mc39ruSbJ4ZIjtDwNfBfZZb92ZIbRf3obAvjDDMOrnjQwPcUCSK9t9XJJkg9/cTnJinhxW/fzWNuuQ2hmGTv9MhqG+70wbVj3JacBO7dvl581S55VJLkjy9QzDuL8xw7DrNyfZr/VbkuTT7T6vS3JIaz+l1XJFkruSnNhKf8pQ4ZvlidHWZ9rD83rztrluPDmk/E7ALcAzGcb6WswwKuoTwEEj/e8BFrfp0eHqHwX2ZvjH6v8wDGu+PfAVYEnr9zvA2XPUcj+wY5ueGVZ91iG1GYbEv4thTKSnA98A9hmta2S7o3U+wjA0xo7AN3lyGO+3AR9o038N/Fqbfh5we5s+pT2eHdvv5zvtMS5lZKhwb95mu/nNcW1NTkzyL9r0PsCy9ZZ/o6quHmM711bVGoAMw18vZfgj/SLgsrYDsh3wwBzbuInhQk2fBT7b2g4DXpPkHW1+dEjty6vq0XaftzEMpHffRuq8rqoeaOv8X+DS1n4z8Btt+pXA/q1mgF2TzAzM97dV9TjweJIHcdh9jcng0FYhw6V0XwkcXFU/yHBp1vWHvv7++uttwPpDcS9i+Ezk1qo6ePZV/j+/xXBtjtcA/zHD1eBmHVI7yUs3cJ89dT4xMv/EyPpPY/id/MN697n++uPep+RnHNpq7AY83ELjBcBBm3n7dwBL0oZVT7J9Ri4NOirJ0xgONX2ZYVjt3YFd2LQhtX+cZPuNd9ugSxmuBzJT28auQ7GxocIlg0NbjS8Ci9qQ46cyXFths6mqHwFHAe9tw3HfyHAludlsB/xVG2r9BuD0qnqETRtS+8zW/7xNLP1EhiHBb2qHwN4yV+fa+FDhkqfjSpL6uMchSerih2HSzyDJh4BD1mv+YFV9bBr1SFuCh6okSV08VCVJ6mJwSJK6GBySpC4GhySpi8EhSery/wCh8vmh5u530AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x = 'airline_sentiment', data = tweets_with_originals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of strategies we could try to rebalance the dataset. The easiest would be oversampling the neutral/positive sentiment tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test split with oversampling ... try SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = tweets_with_originals.airline_sentiment.map({'negative': 0, 'neutral':1, 'positive':2})\n",
    "\n",
    "# test_train split for TFIDF outputs \n",
    "tfidf_learning_inputs = []\n",
    "for M in tfidf_input_mats:\n",
    "    T_train, T_test, y_train, y_test = train_test_split(T, y, test_size=0.3)\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    T_train_sm, y_train_sm = sm.fit_sample(T_train, y_train.ravel())\n",
    "    tfidf_learning_inputs.append([T_train_sm, T_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train_split for Doc2Vec outputs\n",
    "#train\n",
    "tweet_ids = tweets_with_originals.tweet_id.astype(str).values\n",
    "doc2vec_learning_inputs = []\n",
    "for model in doc2vec_models: \n",
    "    X_train, X_test, y_train, y_test = c2.doc2vec_train_test_split(model, tweet_ids, y)\n",
    "    sm = SMOTE()\n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    doc2vec_learning_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that SMOTE balances the number of training samples in each class... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHMJJREFUeJzt3XuYXFWd7vHvS8I9hCSkYYAEgpBRwBGEFlDUYQwnBASTR4gTFBKQcyJngCMKB9HjDMhtcBxFYQRBCAREIcRRAg8jZIKoMHJpJAQSLomAJCYkDblAQC4Jv/PHXj3Z6VRV1wpdXenk/TxPPbX32mvvvap2V72119pVrYjAzMysXps1uwFmZta7ODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4NjEyPpfEk/aXY7apH0CUnPNHH/u0laKalPd9btLSTtJOm3kl6T9N1mt8c2PA6OjZCkz0tqS29oiyT9h6SPN7td9YqI30XE+9dnXUknSbr/Pe7/xYjoFxGru7NuT5H0gqTD38MmJgIvA/0j4qxGfNiQNEDSJEkvpYB6VtLXSstD0mJJfUtlfSUtkRSdtnW0pIclvS7pFUk3SxqSln0jvQ5WSnpT0urS/OzSvl4vla+UdE53Pt6NjYNjIyPpq8D3gUuAnYDdgCuB0c1s14ZkYzo7aJDdgTnRTd8OLr/5l1wG9AP2BrYHPgP8sVOd5cCRpfmjgGWdtn0c8FPgB8BgYF/gLeB+SQMj4pIU7P2AU4Hfd8xHxL6lTe1XKu8XEf+y3g94UxARvm0kN4oX4EpgbI065wM/Kc3fBrwErAB+C+xbWnYUMAd4DfgzcHYqHwzcSfHCXgr8DtgsLdsF+DnQDjwP/J/S9g4C2oBXgcXA96q08TBgQWn+BeBsYFZq563AVhXW2xt4E1idnoflqfwG4CrgLuB14HDg08BjqS3zgfNL2xkGBNA3zd8HXAg8kJ6Le4DBuXXT8vHAn4BXgH9Mj+3wKs9Dxec/LTsamJmOwX8BH0rlNwHvAn9Jz8E5FbY7MB2/doo34juBIaXn6h3g7bT+0Wn6nTT/eOlv7TpgUWrbRUCftOyk9PgvS38fF1Vow5PAmBp/pwF8E7itVDYV+H9ApHml5/KcTutulrZ/Qafyk4D7q+xrr2a/fnvTrekN8K0bDyaMAlZ1vIlVqXM+awfHF4HtgC0pzlRmlpYtAj6RpgcCB6TpfwZ+BGyebp9IL+LNgEeBfwK2AN4HPAcckdb7PXBimu4HHFKljYexbnA8TBFKg4CngFOrrLvOm0N6M1wBHJrauFXax9+k+Q9RBNmYVH8Y64bBH4G/BrZO85euR919KN58P56en3+leEOuFhzVnv8DgCXAwUAfYEJ6jrYsPV8Vt5mW7wAcC2yTjv1twC87PV8XlebPp/Q3k8p+CVwNbAvsmI7Pl0rHYBVwBtAX2LpCG64FZgMnA8MrLA/gg+m4DEi3xaksUp0PpHp7VFj/WxRnFzX/Nkr7cnBk3NxVtXHZAXg5IlbVu0JETIqI1yLiLYo3iP0kbZ8WvwPsI6l/RCyLiD+UyncGdo+Id6IYkwjgI0BLRFwQEW9HxHPAj4FxpfX2kjQ4IlZGxIMZj+3yiFgYEUuBO4D9M9YFuD0iHoiIdyPizYi4LyKeSPOzgJ8Bf1tj/esj4tmI+AswpYv9V6t7HHBHRNwfEW9TBGyt7qBqz///Aq6OiIciYnVETKbonjmkqycBICJeiYifR8QbEfEacDG1H/taJO1E0YV0ZkS8HhFLKM4uxpWqLYyIKyJiVXoeOjsDuBk4HZgjaZ6kIzvVeZPiWP992va0VNZhcLpfVGH7i0rL6/EHSctLtyMy1t3kODg2Lq8Ag6v0Ka9DUh9Jl0r6o6RXKT6pwpoX3LEU3SV/kvQbSR9N5d8B5gH3SHpO0rmpfHdgl/ILEPgGxVgLwCkUn8SflvSIpKMzHttLpek3KM5Ycswvz0g6WNKvJbVLWkHR/13rjSZn/9Xq7lJuR0S8QXHMqqn2/O8OnNXpeR6att8lSdtIulrSn9Jx/y0wIGPsZ3eKM81Fpf1fTXHm0WF+xTWTiPhLFOMPB1J84JkC3CZpUKeqN1J0741P02Uvp/udK+xi59LyehwQEQNKt7sz1t3kODg2Lr+n+EQ2ps76n6cYND+cos96WCoXQEQ8EhGjKd4Qfknx4iadoZwVEe8DjgG+KmkExZvF851egNtFxFFpvbkRcXza3reBqZK2fc+Pem3VPsF3Lv8pxSfYoRGxPUXXm7q5LZ0tAoZ0zEjamuJNs6Jqzz/F83xxp+d5m4j4WceqXbTjLOD9wMER0R/4ZEeTqjWl0/x8ijOcwaX994+1B5vrHliPiFcpLubYFtij0+LfUYTATkDnq+WeARYAY8uFkjajCN0Z9bbB8jg4NiIRsYKi++OHksakT5abSzpSUqWrRLajeAN4haK/+5KOBZK2kPQFSdtHxDsUg8ir07KjJe0lSaXy1RT93K9K+pqkrdMZzQclfSStd4Kkloh4l2JQl45tdqPFwBBJW3RRbztgaUS8KekgihBttKnAMZI+ltr3Laq8Wdd6/im6/05NZ02StK2kT0vaLi1fTDG+VM12FIPny9Mn/PO6aPdiYFh6QyYiFlEM+n9XUn9Jm0naU1JOd9c/SvpIepxbAV+m+JtY6/s7qQv0GOAzabrzsrOBb6q4BH1rSX9FMX7Sn6L7zBrAwbGRiYjvAV+luCKlneLT4ekUn1g7u5HiqpQ/U1y903nM4UTghdSdcSpwQiofDvwnxUDv74Er05jBaooX+f4UV1S9TPEi7hgzGQXMlrSS4vLJcRFR7rPuDvdSDLq+JKlWV8U/ABdIeo0ibKfUqNstImI2Rd/+LRRnH69RDHK/VWWVis9/RLRRjHP8G8VVUfMoBn47/DPFm+lySWdX2O73KQbuX6Y45r/qoum3pftXJHWMs4ynGOCfk9owlcpdRtUEcH1qw0LgfwCfjoiV61SMmJ2eu3U3EnErxfP0lbStORSP7dCIqNUN2Nnjnb7H8f2MdTc56hTiZtZDJPWj+JQ9PCKeb3Z7zOrlMw6zHiTpmNSFuC3F5bhPsOaiBLNewcFh1rNGU3TNLKTo8hvXue/ebEPnriozM8viMw4zM8tS1xfFepvBgwfHsGHDmt0MM7Ne5dFHH305Ilq6qrdRBsewYcNoa2trdjPMzHoVSX+qp567qszMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsy0b5zfEcB/7fzv/G2Brh0e+Mb8h2X7zgbxqyXVtjt396omHbPvSKQxu2bSs8cMYD3b5Nn3GYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVpaHBIGiBpqqSnJT0l6aOSBkmaLmluuh+Y6krS5ZLmSZol6YDSdiak+nMlTWhkm83MrLZGn3H8APhVRHwA2A94CjgXmBERw4EZaR7gSGB4uk0ErgKQNAg4DzgYOAg4ryNszMys5zUsOCT1Bz4JXAcQEW9HxHJgNDA5VZsMjEnTo4Ebo/AgMEDSzsARwPSIWBoRy4DpwKhGtdvMzGpr5BnH+4B24HpJj0m6VtK2wE4RsQgg3e+Y6u8KzC+tvyCVVSs3M7MmaGRw9AUOAK6KiA8Dr7OmW6oSVSiLGuVrryxNlNQmqa29vX192mtmZnVoZHAsABZExENpfipFkCxOXVCk+yWl+kNL6w8BFtYoX0tEXBMRrRHR2tLS0q0PxMzM1mhYcETES8B8Se9PRSOAOcA0oOPKqAnA7Wl6GjA+XV11CLAidWXdDYyUNDANio9MZWZm1gSN/n8cZwA3S9oCeA44mSKspkg6BXgRGJvq3gUcBcwD3kh1iYilki4EHkn1LoiIpQ1ut5mZVdHQ4IiImUBrhUUjKtQN4LQq25kETOre1pmZ2frwN8fNzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyNDQ4JL0g6QlJMyW1pbJBkqZLmpvuB6ZySbpc0jxJsyQdUNrOhFR/rqQJjWyzmZnV1hNnHH8XEftHRGuaPxeYERHDgRlpHuBIYHi6TQSugiJogPOAg4GDgPM6wsbMzHpeM7qqRgOT0/RkYEyp/MYoPAgMkLQzcAQwPSKWRsQyYDowqqcbbWZmhUYHRwD3SHpU0sRUtlNELAJI9zum8l2B+aV1F6SyauVrkTRRUpuktvb29m5+GGZm1qFvg7d/aEQslLQjMF3S0zXqqkJZ1ChfuyDiGuAagNbW1nWWm5lZ92joGUdELEz3S4BfUIxRLE5dUKT7Jan6AmBoafUhwMIa5WZm1gQNCw5J20rarmMaGAk8CUwDOq6MmgDcnqanAePT1VWHACtSV9bdwEhJA9Og+MhUZmZmTdDIrqqdgF9I6tjPTyPiV5IeAaZIOgV4ERib6t8FHAXMA94ATgaIiKWSLgQeSfUuiIilDWy3mZnV0LDgiIjngP0qlL8CjKhQHsBpVbY1CZjU3W00M7N8/ua4mZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZWl4cEjqI+kxSXem+T0kPSRprqRbJW2RyrdM8/PS8mGlbXw9lT8j6YhGt9nMzKrriTOOLwNPlea/DVwWEcOBZcApqfwUYFlE7AVcluohaR9gHLAvMAq4UlKfHmi3mZlV0NDgkDQE+DRwbZoX8ClgaqoyGRiTpkenedLyEan+aOCWiHgrIp4H5gEHNbLdZmZWXaPPOL4PnAO8m+Z3AJZHxKo0vwDYNU3vCswHSMtXpPr/XV5hnf8maaKkNklt7e3t3f04zMwsaVhwSDoaWBIRj5aLK1SNLpbVWmdNQcQ1EdEaEa0tLS3Z7TUzs/r0beC2DwU+I+koYCugP8UZyABJfdNZxRBgYaq/ABgKLJDUF9geWFoq71Bex8zMeljDzjgi4usRMSQihlEMbt8bEV8Afg0cl6pNAG5P09PSPGn5vRERqXxcuupqD2A48HCj2m1mZrU18oyjmq8Bt0i6CHgMuC6VXwfcJGkexZnGOICImC1pCjAHWAWcFhGre77ZZmYGPRQcEXEfcF+afo4KV0VFxJvA2CrrXwxc3LgWmplZvfzNcTMzy+LgMDOzLA4OMzPL4uAwM7MsdQWHpBn1lJmZ2cav5lVVkrYCtgEGSxrImm9x9wd2aXDbzMxsA9TV5bhfAs6kCIlHWRMcrwI/bGC7zMxsA1UzOCLiB8APJJ0REVf0UJvMzGwDVtcXACPiCkkfA4aV14mIGxvULjMz20DVFRySbgL2BGYCHT/3EYCDw8xsE1PvT460AvukHx00M7NNWL3f43gS+KtGNsTMzHqHes84BgNzJD0MvNVRGBGfaUirzMxsg1VvcJzfyEaYmVnvUe9VVb9pdEPMzKx3qPeqqtdY83++twA2B16PiP6NapiZmW2Y6j3j2K48L2kMFf4Zk5mZbfzW69dxI+KXwKe6uS1mZtYL1NtV9dnS7GYU3+vwdzrMzDZB9V5VdUxpehXwAjC621tjZmYbvHrHOE5udEPMzKx3qPcfOQ2R9AtJSyQtlvRzSUMa3TgzM9vw1Ds4fj0wjeL/cuwK3JHKzMxsE1NvcLRExPURsSrdbgBaGtguMzPbQNUbHC9LOkFSn3Q7AXil1gqStpL0sKTHJc2W9K1UvoekhyTNlXSrpC1S+ZZpfl5aPqy0ra+n8mckHbF+D9XMzLpDvcHxReBzwEvAIuA4oKsB87eAT0XEfsD+wChJhwDfBi6LiOHAMuCUVP8UYFlE7AVcluohaR9gHLAvMAq4UlKfOtttZmbdrN7guBCYEBEtEbEjRZCcX2uFKKxMs5unW1B8cXBqKp8MjEnTo9M8afkISUrlt0TEWxHxPDAPf2vdzKxp6g2OD0XEso6ZiFgKfLirlVK31kxgCTAd+COwPCJWpSoLKAbbSffz0/ZXASuAHcrlFdYp72uipDZJbe3t7XU+LDMzy1VvcGwmaWDHjKRB1PEdkIhYHRH7A0MozhL2rlStY7NVllUr77yvayKiNSJaW1o8bm9m1ij1fnP8u8B/SZpK8ab9OeDiencSEcsl3QccAgyQ1DedVQwBFqZqC4ChwAJJfYHtgaWl8g7ldczMrIfVdcYRETcCxwKLgXbgsxFxU611JLVIGpCmtwYOB54Cfk0xuA4wAbg9TU9L86Tl96b/cT4NGJeuutoDGA48XN/DMzOz7lbvGQcRMQeYk7HtnYHJ6QqozYApEXGnpDnALZIuAh4Drkv1rwNukjSP4kxjXNrvbElT0r5XAadFxOqMdpiZWTeqOzhyRcQsKgygR8RzVLgqKiLeBMZW2dbFZHSNmZlZ46zX/+MwM7NNl4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLIuDw8zMsjg4zMwsi4PDzMyyODjMzCyLg8PMzLI4OMzMLEvDgkPSUEm/lvSUpNmSvpzKB0maLmluuh+YyiXpcknzJM2SdEBpWxNS/bmSJjSqzWZm1rVGnnGsAs6KiL2BQ4DTJO0DnAvMiIjhwIw0D3AkMDzdJgJXQRE0wHnAwcBBwHkdYWNmZj2vYcEREYsi4g9p+jXgKWBXYDQwOVWbDIxJ06OBG6PwIDBA0s7AEcD0iFgaEcuA6cCoRrXbzMxq65ExDknDgA8DDwE7RcQiKMIF2DFV2xWYX1ptQSqrVt55HxMltUlqa29v7+6HYGZmScODQ1I/4OfAmRHxaq2qFcqiRvnaBRHXRERrRLS2tLSsX2PNzKxLDQ0OSZtThMbNEfHvqXhx6oIi3S9J5QuAoaXVhwALa5SbmVkTNPKqKgHXAU9FxPdKi6YBHVdGTQBuL5WPT1dXHQKsSF1ZdwMjJQ1Mg+IjU5mZmTVB3wZu+1DgROAJSTNT2TeAS4Epkk4BXgTGpmV3AUcB84A3gJMBImKppAuBR1K9CyJiaQPbbWZmNTQsOCLifiqPTwCMqFA/gNOqbGsSMKn7WmdmZuvL3xw3M7MsDg4zM8vi4DAzsywODjMzy+LgMDOzLA4OMzPL4uAwM7MsDg4zM8vi4DAzsywODjMzy+LgMDOzLA4OMzPL4uAwM7MsDg4zM8vi4DAzsywODjMzy+LgMDOzLA4OMzPL4uAwM7MsDg4zM8vi4DAzsywODjMzy+LgMDOzLA0LDkmTJC2R9GSpbJCk6ZLmpvuBqVySLpc0T9IsSQeU1pmQ6s+VNKFR7TUzs/o08ozjBmBUp7JzgRkRMRyYkeYBjgSGp9tE4CooggY4DzgYOAg4ryNszMysORoWHBHxW2Bpp+LRwOQ0PRkYUyq/MQoPAgMk7QwcAUyPiKURsQyYzrphZGZmPainxzh2iohFAOl+x1S+KzC/VG9BKqtWvg5JEyW1SWprb2/v9oabmVlhQxkcV4WyqFG+bmHENRHRGhGtLS0t3do4MzNbo6eDY3HqgiLdL0nlC4ChpXpDgIU1ys3MrEl6OjimAR1XRk0Abi+Vj09XVx0CrEhdWXcDIyUNTIPiI1OZmZk1Sd9GbVjSz4DDgMGSFlBcHXUpMEXSKcCLwNhU/S7gKGAe8AZwMkBELJV0IfBIqndBRHQecDczsx7UsOCIiOOrLBpRoW4Ap1XZziRgUjc2zczM3oMNZXDczMx6CQeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZXFwmJlZFgeHmZllcXCYmVkWB4eZmWVxcJiZWRYHh5mZZek1wSFplKRnJM2TdG6z22NmtqnqFcEhqQ/wQ+BIYB/geEn7NLdVZmabpl4RHMBBwLyIeC4i3gZuAUY3uU1mZpskRUSz29AlSccBoyLif6b5E4GDI+L0Up2JwMQ0+37gmR5vaM8ZDLzc7EbYevPx67029mO3e0S0dFWpb0+0pBuoQtlaiRcR1wDX9ExzmktSW0S0Nrsdtn58/HovH7tCb+mqWgAMLc0PARY2qS1mZpu03hIcjwDDJe0haQtgHDCtyW0yM9sk9YquqohYJel04G6gDzApImY3uVnNtEl0yW3EfPx6Lx87esnguJmZbTh6S1eVmZltIBwcZmaWxcHRy0kaIOkfSvO7SJrazDZZ1yQNk/T59Vx3ZXe3x7om6VRJ49P0SZJ2KS27dlP6NQuPcfRykoYBd0bEB5vcFMsg6TDg7Ig4usKyvhGxqsa6KyOiXyPbZ7VJuo/i+LU1uy3N4DOOBkufLJ+S9GNJsyXdI2lrSXtK+pWkRyX9TtIHUv09JT0o6RFJF3R8upTUT9IMSX+Q9ISkjp9cuRTYU9JMSd9J+3syrfOQpH1LbblP0oGStpU0Ke3jsdK2rAvrcTxvSL980LF+x9nCpcAn0nH7SvoEe5ukO4B7ahxvWw/puD0tabKkWZKmStpG0oj0GngivSa2TPUvlTQn1f3XVHa+pLPT8WwFbk7Hb+v02mqV9L8l/UtpvydJuiJNnyDp4bTO1ek3+HqniPCtgTdgGLAK2D/NTwFOAGYAw1PZwcC9afpO4Pg0fSqwMk33Bfqn6cHAPIpv1A8Dnuy0vyfT9FeAb6XpnYFn0/QlwAlpegDwLLBts5+r3nBbj+N5A3Bcaf2O43kYxZliR/lJFF90HVTreJe34Vv2cQvg0DQ/CfgmMB/461R2I3AmMIjiJ4s6nu8B6f58irMMgPuA1tL276MIkxaK39XrKP8P4OPA3sAdwOap/EpgfLOfl/W9+YyjZzwfETPT9KMUf8QfA26TNBO4muKNHeCjwG1p+qelbQi4RNIs4D+BXYGdutjvFGBsmv5cabsjgXPTvu8DtgJ2y35Um66c45ljekQsTdPrc7yttvkR8UCa/gkwguJYPpvKJgOfBF4F3gSulfRZ4I16dxAR7cBzkg6RtAPF7+Y9kPZ1IPBI+hsZAbyvGx5TU/SKLwBuBN4qTa+meANYHhH7Z2zjCxSfZg6MiHckvUDxhl9VRPxZ0iuSPgT8PfCltEjAsRGxMf8QZCPlHM9VpC5hSQK2qLHd10vT2cfbulTXgG4UXzg+iOLNfRxwOvCpjP3cSvFB7WngFxER6dhPjoivZ7Z5g+QzjuZ4FXhe0lgo3lAk7ZeWPQgcm6bHldbZHliS3kT+Dtg9lb8GbFdjX7cA5wDbR8QTqexu4Iz0x4ykD7/XB7SJq3U8X6D4pAnFvwLYPE13ddyqHW9bf7tJ+miaPp7iTG6YpL1S2YnAbyT1o3i93EXRdVXpA0Gt4/fvwJi0j1tT2QzgOEk7AkgaJKnXHlMHR/N8AThF0uPAbNb8f5Ezga9Kepiiu2NFKr8ZaJXUltZ9GiAiXgEekPSkpO9U2M9UigCaUiq7kOINbFYaSL+wWx/Zpqna8fwx8LfpeB7MmrOKWcAqSY9L+kqF7VU83vaePAVMSN1/g4DLgJMpuhifAN4FfkQRCHemer+hGCvs7AbgRx2D4+UFEbEMmEPxE+UPp7I5FGMq96TtTmf9ujM3CL4cdwMjaRvgL+n0dhzFQLmvqDF7D+TL1ruVxzg2PAcC/5a6kZYDX2xye8zM1uIzDjMzy+IxDjMzy+LgMDOzLA4OMzPL4uAwM7MsDg4zM8vy/wH+/72YanzVhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x = tfidf_learning_inputs[0][2])\n",
    "_ = plt.title('Classes in training set after SMOTE')\n",
    "locs, labels = plt.xticks()\n",
    "_ = plt.xticks(locs, ['negative', 'neutral', 'positive'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF input sentiment analysis\n",
    "Basic logistic regression with one-versus-rest (OVR) multiclass scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram TF-IDF:\t Train Accuracy 0.8450520833333334\n",
      "1-gram TF-IDF:\t Test Accuracy 0.7438378253858557\n",
      "2-gram TF-IDF:\t Train Accuracy 0.8386255800615257\n",
      "2-gram TF-IDF:\t Test Accuracy 0.7413038470398525\n",
      "3-gram TF-IDF:\t Train Accuracy 0.8447172384849438\n",
      "3-gram TF-IDF:\t Test Accuracy 0.7442985487214927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf_log_models = []\n",
    "for i, ngram_model in enumerate(tfidf_learning_inputs): \n",
    "    lr = LogisticRegression(solver = 'saga', multi_class='multinomial', max_iter = 200)\n",
    "    lr.fit(ngram_model[0], ngram_model[2])\n",
    "    print('{}-gram TF-IDF:\\t Train Accuracy {}'.format(i+1,lr.score(ngram_model[0], ngram_model[2])))\n",
    "    print('{}-gram TF-IDF:\\t Test Accuracy {}'.format(i+1,lr.score(ngram_model[1], ngram_model[3])))\n",
    "    tfidf_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec input sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the sum of words embedding which is described [here](https://white.ucc.asn.au/publications/White2015SentVecMeaning.pdf). We just take the sum of the word vectors contained in a tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vec = tweets_with_originals.set_index('tweet_id').airline_sentiment.map({'negative': 0, 'neutral':1, 'positive':2})\n",
    "tokenized_input_ser = pd.Series(tokenized_input, index=tweets_with_originals.tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sow_inputs = []\n",
    "for model in word2vec_models:\n",
    "    X_train, X_test, y_train, y_test = c2.word2vec_train_test_split(model_word2vec, tokenized_input_ser, target_vec)\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    word2vec_sow_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_avg_inputs = []\n",
    "for model in word2vec_models:\n",
    "    X_train, X_test, y_train, y_test = c2.word2vec_train_test_split(model_word2vec, tokenized_input_ser, target_vec, embedding = 'avge')\n",
    "    sm = SMOTE() # smarter upsampling \n",
    "    X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train.ravel())\n",
    "    word2vec_avg_inputs.append([X_train_sm, X_test, y_train_sm, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Sum of words input sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Sum of words Model 1:\t Accuracy 0.7069799585348998\n",
      "Word2Vec Sum of words Model 2:\t Accuracy 0.7115871918912693\n",
      "Word2Vec Sum of words Model 3:\t Accuracy 0.7108961068878139\n",
      "Word2Vec Sum of words Model 4:\t Accuracy 0.7157337019120018\n",
      "Word2Vec Sum of words Model 5:\t Accuracy 0.7161944252476388\n",
      "Word2Vec Sum of words Model 6:\t Accuracy 0.7168855102510943\n",
      "Word2Vec Sum of words Model 7:\t Accuracy 0.7067495968670813\n",
      "Word2Vec Sum of words Model 8:\t Accuracy 0.7026030868463488\n",
      "Word2Vec Sum of words Model 9:\t Accuracy 0.7108961068878139\n",
      "Word2Vec Sum of words Model 10:\t Accuracy 0.7145818935729095\n",
      "Word2Vec Sum of words Model 11:\t Accuracy 0.7173462335867312\n",
      "Word2Vec Sum of words Model 12:\t Accuracy 0.7145818935729095\n"
     ]
    }
   ],
   "source": [
    "word2vec_sow_log_models = []\n",
    "for i, sow_model in enumerate(word2vec_sow_inputs): \n",
    "    lr = LogisticRegression(solver = 'lbfgs', multi_class='auto', max_iter = 2000)\n",
    "    lr.fit(sow_model[0], sow_model[2])\n",
    "    print('Word2Vec Sum of words Model {}:\\t Accuracy {}'.format(i+1,lr.score(sow_model[1], sow_model[3])))\n",
    "    word2vec_sow_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Avg embedding input sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Mean Embedding Model 1:\t Accuracy 0.7127390002303616\n",
      "Word2Vec Mean Embedding Model 2:\t Accuracy 0.7092835752130845\n",
      "Word2Vec Mean Embedding Model 3:\t Accuracy 0.7228749136143746\n",
      "Word2Vec Mean Embedding Model 4:\t Accuracy 0.7251785302925593\n",
      "Word2Vec Mean Embedding Model 5:\t Accuracy 0.7088228518774476\n",
      "Word2Vec Mean Embedding Model 6:\t Accuracy 0.7198802119327344\n",
      "Word2Vec Mean Embedding Model 7:\t Accuracy 0.7201105736005529\n",
      "Word2Vec Mean Embedding Model 8:\t Accuracy 0.714351531905091\n",
      "Word2Vec Mean Embedding Model 9:\t Accuracy 0.7164247869154573\n",
      "Word2Vec Mean Embedding Model 10:\t Accuracy 0.7194194885970975\n",
      "Word2Vec Mean Embedding Model 11:\t Accuracy 0.7228749136143746\n",
      "Word2Vec Mean Embedding Model 12:\t Accuracy 0.7120479152269062\n"
     ]
    }
   ],
   "source": [
    "word2vec_avg_log_models = []\n",
    "for i, avg_model in enumerate(word2vec_avg_inputs): \n",
    "    lr = LogisticRegression(solver = 'lbfgs', multi_class='auto', max_iter = 2000)\n",
    "    lr.fit(avg_model[0], avg_model[2])\n",
    "    print('Word2Vec Mean Embedding Model {}:\\t Accuracy {}'.format(i+1,lr.score(avg_model[1], avg_model[3])))\n",
    "    word2vec_avg_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average and sum of word embeddings for tweets seem to perform comparably: this is in line with what we'd expect from the literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec input sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.6268140981340705\n",
      "Model 2: \t Accuracy 0.5381248560239577\n",
      "Model 3: \t Accuracy 0.6242801197880673\n",
      "Model 4: \t Accuracy 0.5401981110343239\n",
      "Model 5: \t Accuracy 0.6185210780926054\n",
      "Model 6: \t Accuracy 0.5560930661137987\n",
      "Model 7: \t Accuracy 0.6749596867081318\n",
      "Model 8: \t Accuracy 0.5816632112416494\n",
      "Model 9: \t Accuracy 0.6685095600092145\n",
      "Model 10: \t Accuracy 0.6053904630269523\n",
      "Model 11: \t Accuracy 0.6763418567150427\n",
      "Model 12: \t Accuracy 0.6164478230822391\n",
      "Model 13: \t Accuracy 0.6821008984105045\n",
      "Model 14: \t Accuracy 0.585348997926745\n",
      "Model 15: \t Accuracy 0.6952315134761575\n",
      "Model 16: \t Accuracy 0.6120709513936881\n",
      "Model 17: \t Accuracy 0.7037548951854411\n",
      "Model 18: \t Accuracy 0.6288873531444368\n"
     ]
    }
   ],
   "source": [
    "doc2vec_log_models = []\n",
    "for i,model in enumerate(doc2vec_learning_inputs): \n",
    "    lr = LogisticRegression(solver='saga', multi_class = 'multinomial', max_iter = 2000)\n",
    "    lr.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1, lr.score(model[1], model[3])))\n",
    "    doc2vec_log_models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is poor here: instability was observed in results when training the various Doc2Vec models. I think that we need more training data: the number of tweets we have is pretty low for the complexity of the doc2vec NN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram TF-IDF:\t Accuracy 0.7053674268601705\n",
      "2-gram TF-IDF:\t Accuracy 0.7009905551716195\n",
      "3-gram TF-IDF:\t Accuracy 0.6975351301543423\n"
     ]
    }
   ],
   "source": [
    "tfidf_rf_models = []\n",
    "for i, ngram_model in enumerate(tfidf_learning_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 200, criterion = 'gini', max_features = 'sqrt', max_depth = 20)\n",
    "    rf.fit(ngram_model[0], ngram_model[2])\n",
    "    print('{}-gram TF-IDF:\\t Accuracy {}'.format(i+1,rf.score(ngram_model[1], ngram_model[3])))\n",
    "    tfidf_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.7254088919603778\n",
      "Model 2: \t Accuracy 0.7228749136143746\n",
      "Model 3: \t Accuracy 0.7217231052752822\n",
      "Model 4: \t Accuracy 0.7166551485832757\n",
      "Model 5: \t Accuracy 0.7297857636489288\n",
      "Model 6: \t Accuracy 0.7254088919603778\n",
      "Model 7: \t Accuracy 0.7242570836212854\n",
      "Model 8: \t Accuracy 0.7272517853029256\n",
      "Model 9: \t Accuracy 0.7224141902787377\n",
      "Model 10: \t Accuracy 0.7247178069569223\n",
      "Model 11: \t Accuracy 0.7364662520156646\n",
      "Model 12: \t Accuracy 0.7161944252476388\n"
     ]
    }
   ],
   "source": [
    "word2vec_sow_rf_models = []\n",
    "for i, model in enumerate(word2vec_sow_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    word2vec_sow_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.7150426169085464\n",
      "Model 2: \t Accuracy 0.7168855102510943\n",
      "Model 3: \t Accuracy 0.7362358903478461\n",
      "Model 4: \t Accuracy 0.7313982953236582\n",
      "Model 5: \t Accuracy 0.7228749136143746\n",
      "Model 6: \t Accuracy 0.7307072103202027\n",
      "Model 7: \t Accuracy 0.7212623819396452\n",
      "Model 8: \t Accuracy 0.7184980419258236\n",
      "Model 9: \t Accuracy 0.718267680258005\n",
      "Model 10: \t Accuracy 0.7242570836212854\n",
      "Model 11: \t Accuracy 0.7332411886662059\n",
      "Model 12: \t Accuracy 0.7122782768947247\n"
     ]
    }
   ],
   "source": [
    "word2vec_avg_rf_models = []\n",
    "for i, model in enumerate(word2vec_avg_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    word2vec_avg_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \t Accuracy 0.6763418567150427\n",
      "Model 2: \t Accuracy 0.6457037548951854\n",
      "Model 3: \t Accuracy 0.6657452199953927\n",
      "Model 4: \t Accuracy 0.6387929048606312\n",
      "Model 5: \t Accuracy 0.6839437917530523\n",
      "Model 6: \t Accuracy 0.6491591799124625\n",
      "Model 7: \t Accuracy 0.7134300852338171\n",
      "Model 8: \t Accuracy 0.6680488366735775\n",
      "Model 9: \t Accuracy 0.7062888735314443\n",
      "Model 10: \t Accuracy 0.6673577516701221\n",
      "Model 11: \t Accuracy 0.714351531905091\n",
      "Model 12: \t Accuracy 0.663441603317208\n",
      "Model 13: \t Accuracy 0.7115871918912693\n",
      "Model 14: \t Accuracy 0.6701220916839438\n",
      "Model 15: \t Accuracy 0.7102050218843584\n",
      "Model 16: \t Accuracy 0.6668970283344852\n",
      "Model 17: \t Accuracy 0.7191891269292789\n",
      "Model 18: \t Accuracy 0.677954388389772\n"
     ]
    }
   ],
   "source": [
    "doc2vec_rf_models = []\n",
    "for i, model in enumerate(doc2vec_learning_inputs): \n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features = 'sqrt', max_depth = 10)\n",
    "    rf.fit(model[0], model[2])\n",
    "    print('Model {}: \\t Accuracy {}'.format(i+1,rf.score(model[1], model[3])))\n",
    "    doc2vec_rf_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(doc2vec_models):\n",
    "    model.save('doc2vec_{}.model'.format(idx))\n",
    "for idx, model in enumerate(word2vec_models):\n",
    "    model.save('word2vec_{}.model'.format(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 61.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 225.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 435.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With thanks to towardsdatascience: \n",
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=False)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(word2vec_sow_inputs[10][0], word2vec_sow_inputs[10][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 90}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_sow_models[10].alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 11: \t Accuracy 0.7542041004376872\n"
     ]
    }
   ],
   "source": [
    "model=word2vec_sow_inputs[10]\n",
    "rf = RandomForestClassifier(n_estimators = 1800, criterion = 'gini', max_features = 'auto', max_depth = 90, \n",
    "                               min_samples_split=2, min_samples_leaf = 1)\n",
    "rf.fit(model[0], model[2])\n",
    "print('Model {}: \\t Accuracy {}'.format(11,rf.score(model[1], model[3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 11: \t Accuracy 0.7233356369500116\n"
     ]
    }
   ],
   "source": [
    "model=doc2vec_learning_inputs[16]\n",
    "rf = RandomForestClassifier(n_estimators = 1800, criterion = 'gini', max_features = 'auto', max_depth = 90, \n",
    "                               min_samples_split=2, min_samples_leaf = 1)\n",
    "rf.fit(model[0], model[2])\n",
    "print('Model {}: \\t Accuracy {}'.format(11,rf.score(model[1], model[3])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
